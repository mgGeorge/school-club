{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwO7dPCrskum"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "j54JVDQ5ssWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()  # download Boston database\n",
        "print( \"Type of boston dataset:\", type(boston))"
      ],
      "metadata": {
        "id": "TaEyF8nRssds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston.keys())"
      ],
      "metadata": {
        "id": "Vpo5LVaUssfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston['DESCR'])"
      ],
      "metadata": {
        "id": "AxYv2Ggasshn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "boston_df = pd.DataFrame(boston['data'] )  # transition to DataFrame\n",
        "boston_df.head() "
      ],
      "metadata": {
        "id": "74rLMUy6ssjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.head(10)"
      ],
      "metadata": {
        "id": "3kRJDmTpssmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.columns = boston['feature_names']  # add special row\n",
        "boston_df.head()"
      ],
      "metadata": {
        "id": "t611FzEnssoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df['PRICE']= boston['target']  # add price colomn\n",
        "boston_df.head()"
      ],
      "metadata": {
        "id": "lv4yoN2sssqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#check for missing values\n",
        "print(np.sum(np.isnan(boston_df)))"
      ],
      "metadata": {
        "id": "bAUtRdlGssso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "eGbw6pPNssus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(boston_df['PRICE']);"
      ],
      "metadata": {
        "id": "AATfAdYhtMJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(boston_df);"
      ],
      "metadata": {
        "id": "rfiI6An0tMN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will throw and error at import if haven't upgraded. \n",
        "# from sklearn.cross_validation  import train_test_split \n",
        "from sklearn.model_selection  import train_test_split\n",
        "#y is the dependent variable.\n",
        "y = boston_df['PRICE']\n",
        "#As we know, iloc is used to slice the array by index number. Here this is the matrix of \n",
        "#independent variables.\n",
        "X = boston_df.iloc[:,0:13]\n",
        "\n",
        "# Split the data into a training set and a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "TzYL-ItFtTbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lm = LinearRegression()\n",
        "lm.fit( X_train, y_train )"
      ],
      "metadata": {
        "id": "YFjBBMEwtTdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('labels\\n',X.columns)\n",
        "print('Coefficients: \\n', lm.coef_)  # 各特征 weight\n",
        "print('Intercept: \\n', lm.intercept_)  # 截距\n",
        "print('R2 for Train)', lm.score( X_train, y_train ))  # 訓練集數據分數\n",
        "print('R2 for Test (cross validation)', lm.score(X_test, y_test))  # 測試集數據分數"
      ],
      "metadata": {
        "id": "UpnhePIRtTfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternately, we can show the results in a dataframe using the zip command.\n",
        "pd.DataFrame(\n",
        "    list(zip(X.columns, lm.coef_)),\n",
        "    columns=['features', 'estimatedCoeffs']\n",
        ")"
      ],
      "metadata": {
        "id": "4nW3G3aatfgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(lm, X_train, y_train, cv=8)  # cv 為測試次數\n",
        "print(\"R2:\", scores, \"\\n R2_avg: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "metadata": {
        "id": "qr-PjOcptfiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump( lm, open( 'lm_reg_boston.p', 'wb' ) )  # 儲存 model"
      ],
      "metadata": {
        "id": "im4kYctQtjpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pickled object. \n",
        "lm_pickled = pickle.load( open( \"lm_reg_boston.p\", \"rb\" ) )  # 讀取 model\n",
        "\n",
        "lm_pickled.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "4FdouRBOtjrB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}